# ex-GPT + RAGFlow 통합 환경 설정

# ============= 오픈소스 LLM 설정 =============
# Ollama 서버 URL (로컬 오픈소스 모델 사용)
OLLAMA_BASE_URL=http://localhost:11434

# vLLM 서버 URL (고성능 오픈소스 모델 서빙)
VLLM_BASE_URL=http://localhost:8000

# ============= 기본 서버 설정 =============
FLASK_ENV=development
FLASK_DEBUG=False
SERVER_HOST=0.0.0.0
SERVER_PORT=5001

# ============= RAGFlow 설정 =============
# RAGFlow 서버 주소 (Docker 실행 시)
RAGFLOW_HOST=http://localhost:8080

# RAGFlow API 키 (RAGFlow 웹 인터페이스에서 생성)
# 생성 방법: http://localhost:8080 → 설정 → API 키 생성
RAGFLOW_API_KEY=your_ragflow_api_key_here

# RAGFlow 활성화 여부
RAGFLOW_ENABLED=true

# RAGFlow 기본 어시스턴트 ID (RAGFlow에서 생성한 채팅 어시스턴트의 ID)
# 생성 방법: RAGFlow 웹 인터페이스 → Chat → 새 어시스턴트 생성 → ID 복사
RAGFLOW_ASSISTANT_ID=your_assistant_id_here

# ============= 데이터베이스 설정 =============
# MySQL (RAGFlow용)
MYSQL_HOST=localhost
MYSQL_PORT=3306
MYSQL_USER=ragflow
MYSQL_PASSWORD=ragflow123
MYSQL_DATABASE=ragflow

# Redis (RAGFlow용)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=ragflow123

# ============= 스토리지 설정 =============
# MinIO (RAGFlow용)
MINIO_HOST=localhost
MINIO_PORT=9000
MINIO_USER=ragflow
MINIO_PASSWORD=ragflow123

# Elasticsearch (RAGFlow용)
ELASTICSEARCH_HOST=localhost
ELASTICSEARCH_PORT=9200

# ============= AI 모델 설정 =============
# 로컬 모델 경로
MODEL_CACHE_DIR=D:/huggingface_cache

# Florence-2 모델 설정
FLORENCE_MODEL_PATH=microsoft/Florence-2-large

# ============= 로깅 설정 =============
LOG_LEVEL=INFO
LOG_FILE=logs/ex-gpt.log

# ============= 보안 설정 =============
SECRET_KEY=your_secret_key_here
JWT_SECRET_KEY=your_jwt_secret_key_here

# ============= 업로드 설정 =============
UPLOAD_FOLDER=data/uploads
MAX_CONTENT_LENGTH=50000000  # 50MB

# ============= 기타 설정 =============
# 개발 모드
DEVELOPMENT_MODE=true

# API 요청 제한
RATE_LIMIT_PER_MINUTE=60

# 세션 타임아웃 (초)
SESSION_TIMEOUT=3600
