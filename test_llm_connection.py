#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
LLM ì—°ê²° í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import requests
import json

def test_ollama():
    """Ollama ì—°ê²° í…ŒìŠ¤íŠ¸"""
    try:
        # Ollama ìƒíƒœ í™•ì¸
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json()
            print("âœ… Ollama ì—°ê²° ì„±ê³µ!")
            print(f"ğŸ“¦ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {[m['name'] for m in models.get('models', [])]}")
            return True
        else:
            print(f"âŒ Ollama ìƒíƒœ ì˜¤ë¥˜: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ Ollama ì—°ê²° ì‹¤íŒ¨: {e}")
        return False

def test_qwen_model():
    """Qwen ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    try:
        test_prompt = "ì•ˆë…•í•˜ì„¸ìš”? ê°„ë‹¨íˆ ì¸ì‚¬í•´ì£¼ì„¸ìš”."
        
        response = requests.post(
            "http://localhost:11434/api/generate",
            json={
                "model": "qwen3:8b",
                "prompt": test_prompt,
                "stream": False
            },
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            answer = result.get('response', 'ì‘ë‹µ ì—†ìŒ')
            print("âœ… Qwen3:8b ëª¨ë¸ ì‘ë‹µ ì„±ê³µ!")
            print(f"ğŸ¤– ì‘ë‹µ: {answer[:100]}...")
            return True
        else:
            print(f"âŒ ëª¨ë¸ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"âŒ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_langgraph_server():
    """LangGraph ì„œë²„ í…ŒìŠ¤íŠ¸"""
    try:
        response = requests.get("http://localhost:5000/api/health", timeout=5)
        if response.status_code == 200:
            print("âœ… LangGraph ì„œë²„ ì‹¤í–‰ ì¤‘!")
            return True
        else:
            print(f"âŒ ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
        return False

if __name__ == "__main__":
    print("ğŸ” ex-GPT LLM ì—°ê²° ìƒíƒœ í™•ì¸")
    print("=" * 40)
    
    # 1. Ollama ì—°ê²° í…ŒìŠ¤íŠ¸
    print("\n1ï¸âƒ£ Ollama ì„œë¹„ìŠ¤ í™•ì¸...")
    ollama_ok = test_ollama()
    
    # 2. Qwen ëª¨ë¸ í…ŒìŠ¤íŠ¸
    if ollama_ok:
        print("\n2ï¸âƒ£ Qwen3:8b ëª¨ë¸ í…ŒìŠ¤íŠ¸...")
        model_ok = test_qwen_model()
    else:
        print("\n2ï¸âƒ£ Qwen3:8b ëª¨ë¸ í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ (Ollama ì—°ê²° ì‹¤íŒ¨)")
        model_ok = False
    
    # 3. LangGraph ì„œë²„ í…ŒìŠ¤íŠ¸
    print("\n3ï¸âƒ£ LangGraph ì„œë²„ í™•ì¸...")
    server_ok = test_langgraph_server()
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 40)
    print("ğŸ“Š ì—°ê²° ìƒíƒœ ìš”ì•½:")
    print(f"   Ollama: {'âœ… ì •ìƒ' if ollama_ok else 'âŒ ì˜¤ë¥˜'}")
    print(f"   Qwen3:8b: {'âœ… ì •ìƒ' if model_ok else 'âŒ ì˜¤ë¥˜'}")
    print(f"   LangGraph: {'âœ… ì •ìƒ' if server_ok else 'âŒ ì˜¤ë¥˜'}")
    
    if all([ollama_ok, model_ok]):
        print("\nğŸ‰ ëª¨ë“  LLM ì—°ê²°ì´ ì •ìƒì…ë‹ˆë‹¤!")
        print("ğŸ“± ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:5000 ì ‘ì† ê°€ëŠ¥")
    else:
        print("\nâš ï¸  ì¼ë¶€ ì„œë¹„ìŠ¤ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
        if not ollama_ok:
            print("   - Ollama ì„œë¹„ìŠ¤ë¥¼ ì‹œì‘í•˜ì„¸ìš”: ollama serve")
        if not model_ok and ollama_ok:
            print("   - Qwen3:8b ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”: ollama pull qwen3:8b")
        if not server_ok:
            print("   - LangGraph ì„œë²„ë¥¼ ì‹œì‘í•˜ì„¸ìš”: python server_langgraph.py")
