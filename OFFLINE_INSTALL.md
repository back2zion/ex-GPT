# ex-GPT μ™„μ „ μ¤ν”„λΌμΈ μ„¤μΉ κ°€μ΄λ“

## π”’ Air-Gapped ν™κ²½ μ™„μ „ μ¤ν”„λΌμΈ μ„¤μΉ

> **μ¤‘μ”**: μ΄ κ°€μ΄λ“λ” μΈν„°λ„· μ—°κ²°μ΄ μ „ν€ μ—†λ” μ™„μ „ κ²©λ¦¬λ ν™κ²½μ—μ„μ μ„¤μΉλ¥Ό λ‹¤λ£Ήλ‹λ‹¤.

### 1λ‹¨κ³„: μ¤ν”„λΌμΈ ν¨ν‚¤μ§€ μ¤€λΉ„ (μΈν„°λ„· μ—°κ²°λ λ‹¤λ¥Έ μ‹μ¤ν…μ—μ„)

#### Python ν¨ν‚¤μ§€ λ‹¤μ΄λ΅λ“
```bash
# μΈν„°λ„· μ—°κ²°λ μ‹μ¤ν…μ—μ„ μ‹¤ν–‰
pip download -r requirements.offline.txt -d offline_packages/
```

#### Ollama μ¤ν”„λΌμΈ μ„¤μΉ νμΌ μ¤€λΉ„
1. https://ollama.ai/download μ—μ„ Windows λ²„μ „ λ‹¤μ΄λ΅λ“
2. λ¨λΈ νμΌ μ¤€λΉ„:
   - `ollama pull qwen2.5:7b` (μ•½ 4.1GB)
   - λ¨λΈ νμΌ μ„μΉ: `~/.ollama/models/`

### 2λ‹¨κ³„: Air-Gapped μ‹μ¤ν…μΌλ΅ νμΌ μ „μ†΅

ν•„μ”ν• νμΌλ“¤μ„ USB/μ™Έμ¥λ””μ¤ν¬λ΅ λ³µμ‚¬:
```
ex-gpt-offline-package/
β”β”€β”€ ex-gpt-demo/                 # μ „μ²΄ ν”„λ΅μ νΈ
β”β”€β”€ offline_packages/            # Python ν¨ν‚¤μ§€λ“¤
β”β”€β”€ ollama-windows-amd64.exe     # Ollama μ„¤μΉ νμΌ
β””β”€β”€ ollama-models/               # λ―Έλ¦¬ λ‹¤μ΄λ΅λ“λ λ¨λΈ
    β””β”€β”€ qwen2.5:7b/
```

### 3λ‹¨κ³„: μ¤ν”„λΌμΈ μ‹μ¤ν…μ—μ„ μ„¤μΉ

#### Python μμ΅΄μ„± μ„¤μΉ
```cmd
cd ex-gpt-demo
pip install --no-index --find-links ../offline_packages -r requirements.offline.txt
```

#### Ollama μ„¤μΉ
```cmd
# Ollama μ„¤μΉ
..\ollama-windows-amd64.exe

# λ¨λΈ νμΌ λ³µμ‚¬ (μ‚¬μ©μ ν™ λ””λ ‰ν† λ¦¬λ΅)
xcopy ..\ollama-models %USERPROFILE%\.ollama\models\ /E /I
```

### 4λ‹¨κ³„: μ‹μ¤ν… μ‹¤ν–‰

```cmd
# Ollama μ„λ²„ μ‹μ‘
start ollama serve

# ex-GPT μ¤ν”„λΌμΈ μ„λ²„ μ‹μ‘
start_offline.bat
```

### 5λ‹¨κ³„: μ ‘μ† ν™•μΈ

- μ›Ή λΈλΌμ°μ €μ—μ„ `http://localhost:5000` μ ‘μ†
- Ollama API: `http://localhost:11434`

## π”§ μ¤ν”„λΌμΈ ν™κ²½ μµμ ν™”

### λ©”λ¨λ¦¬ μ‚¬μ©λ‰ μµμ ν™”
- Qwen2.5:7B λ¨λΈ: μµμ† 8GB RAM κ¶μ¥
- GPU μ‚¬μ©μ‹: VRAM 8GB+ κ¶μ¥
- CPU μ „μ©: 16GB+ RAM κ¶μ¥

### μ¤ν† λ¦¬μ§€ μ”κµ¬μ‚¬ν•­
- ν”„λ΅μ νΈ νμΌ: ~500MB
- Ollama + λ¨λΈ: ~5GB
- λ΅κ·Έ/μ—…λ΅λ“ κ³µκ°„: 1GB+

### λ³΄μ• μ„¤μ •
- λ„¤νΈμ›ν¬ λ°©ν™”λ²½: 5000, 11434 ν¬νΈλ§ ν—μ©
- νμΌ μ—…λ΅λ“ μ ν•: 16MB
- λ΅κ·Έ λ λ²¨: INFO (λ””λ²„κ·Έ μ •λ³΄ μµμ†ν™”)

## π¨ λ¬Έμ  ν•΄κ²°

### Ollama μ—°κ²° μ‹¤ν¨
```cmd
# Ollama ν”„λ΅μ„Έμ¤ ν™•μΈ
tasklist | findstr ollama

# ν¬νΈ μ‚¬μ© ν™•μΈ
netstat -an | findstr 11434
```

### Python ν¨ν‚¤μ§€ μ¤λ¥
```cmd
# μ¤ν”„λΌμΈ ν¨ν‚¤μ§€ μ¬μ„¤μΉ
pip install --force-reinstall --no-index --find-links offline_packages flask
```

### λ©”λ¨λ¦¬ λ¶€μ΅±
```cmd
# CPU μ „μ© λ¨λ“λ΅ μ‹¤ν–‰
set OLLAMA_NUM_PARALLEL=1
set OLLAMA_MAX_LOADED_MODELS=1
```
